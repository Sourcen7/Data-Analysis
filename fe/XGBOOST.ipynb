{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataset was taken form Mercari Price Suggestion Challenge\n",
    "#   https://www.kaggle.com/c/mercari-price-suggestion-challenge\n",
    "#\n",
    "#  Second feature engineering: item discription detalisation for dummy variables\n",
    "\n",
    "\n",
    "#import libs for data manipulation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "train = pd.read_csv('C:/temp/train.tsv', sep='\\t' ,nrows= 1000)\n",
    "#print (train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create dummy varibles for brand\n",
    "train2=pd.DataFrame(train['brand_name'].str.replace(' ','').replace('.','').str.lower())\n",
    "#print(train2)\n",
    "dum=pd.get_dummies(train2['brand_name'])\n",
    "#print(dum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load name words for dummy variables\n",
    "df1=pd.read_csv(r'c:\\Temp\\dum.txt',delimiter=' ').reset_index()\n",
    "df1['word']=df1['word'].str.replace('[','').str.replace(']','').str.replace(\"'\",\"\")\n",
    "#print (df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load discription words for dummy variables\n",
    "df2=pd.read_csv(r'c:\\Temp\\dum1.txt',delimiter=' ').reset_index()\n",
    "df2['word']=df2['word'].str.replace('[','').str.replace(']','').str.replace(\"'\",\"\")\n",
    "#print (df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dumf=pd.concat([df1, df2], join='inner', join_axes=None, ignore_index=False,\n",
    "          keys=None, levels=None, names=None, verify_integrity=False,\n",
    "          copy=True)\n",
    "dumf['i']=1\n",
    "dump=pd.pivot_table(dumf, index=['word'],values=['i'],aggfunc='count').reset_index()\n",
    "dumpf=dump.loc[dump['word']!='word'].drop(['i'],axis=1)\n",
    "#print(dumpf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_id' 'name' 'item_condition_id' 'category_name' 'brand_name' 'price'\n",
      " 'shipping' 'item_description' 'W10x13' 'W14k' 'W6/6s' 'Wair' 'Wauthentic'\n",
      " 'Wbag,' 'Wbeats' 'Wbelly' 'Wburberry' 'Wburch' 'Wcamera' 'Wcarters'\n",
      " 'Wchanel' 'Wchoker' 'Wdecal' 'Wdust' 'Welf' 'Weyelashes' 'Weyeliner'\n",
      " 'Wfidget' 'Wflowy' 'Wforever' 'Wgucci' 'Wipad' 'Wjordan' 'Wkate' 'Wkendra'\n",
      " 'Wkors' 'Wlanyard' 'Wlaptop' 'Wlashes' 'Wlouis' 'Wlv' 'Wmascara'\n",
      " 'Wmaybelline' 'Wmichael' 'Wmk' 'Wnail' 'Wnose' 'Wnyx' 'Wpatch' 'Wpoly'\n",
      " 'Wpolymailers' 'Wpopsocket' 'Wprotector' 'Wretro' 'Wrue' 'Wsample'\n",
      " 'Wsarah' 'Wsatchel' 'Wscott' 'Wsilicone' 'Wslime' 'Wspade' 'Wspinner'\n",
      " 'Wsticker' 'Wstickers' 'Wthin' 'Wtiffany' 'Wtory' 'Wugg' 'Wvuitton']\n"
     ]
    }
   ],
   "source": [
    "#make dummy variables for name and item discription\n",
    "for i in range(len(dumpf)):\n",
    "    train['W'+dumpf[i:i+1].to_string(header= False,\n",
    "                                 index= False)]=np.where((train['name'].str.lower()).str\\\n",
    "                                                         .find(dumpf[i:i+1].to_string(header= False, index= False))>-1,4,0)\\\n",
    "    +np.where((train['item_description'].str.lower()).str.find(dumpf[i:i+1].to_string(header= False, index= False))>-1,2,0)\n",
    "print(train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add dymmy for brand variables to main dataframe\n",
    "train3 = pd.concat([train, dum], axis=1)\n",
    "#print (train3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split our sample for train and test subsample\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = train3.drop(['train_id','price','name','category_name','brand_name','item_description'], axis=1)\n",
    "y = train3['price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#put in matrix our sample\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(X.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set paramtres for model\n",
    "param = {\n",
    "    'max_depth': 30,  # the maximum depth of each tree\n",
    "    'eta': 0.1,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 1000\n",
    "}  # the number of classes that exist in this datset\n",
    "num_round = 50  # the number of training iterations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train model\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array precision: 0.002938045561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#calculate precision score\n",
    "from sklearn.metrics import precision_score\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print (\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bst.dump_model('dump.raw.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
